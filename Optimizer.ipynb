{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Iqr5-ISQTy5h",
        "outputId": "bff241ac-980e-47de-bb04-e231561b71ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fb8cc82c1276>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optimizer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import optimizer as optim\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_seed(seed):\n",
        "     torch.manual_seed(seed)\n",
        "     torch.cuda.manual_seed_all(seed)\n",
        "     np.random.seed(seed)\n",
        "     random.seed(seed)\n",
        "     torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(20)"
      ],
      "metadata": {
        "id": "XpvjKmLN7Y5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data, Model, Training, Valid"
      ],
      "metadata": {
        "id": "HVuxcPnWWBsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "DwIukz_lWhkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeroDNDlWGkB",
        "outputId": "a839089d-5cc8-4e9e-c9ec-0876b0c5d8bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 353724454.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 62344670.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 150348733.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 24773119.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_8BvRClCWi2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpEm6GvCWlHJ",
        "outputId": "58db0b48-c864-4133-96bb-619954e7acfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|    | torch optimizer acc  | custom optimizer acc |\n",
        "  ----  | ----  | --- |\n",
        "| SGD  | 72.4% | 72.4% |\n",
        "| Momentum SGD  | 89.0% | 87.2% |\n",
        "| Nestrov SGD  | 90.1% | 90.1% |\n",
        "| Adam | 97.3% | 97.7% |\n",
        "| Nadam | 97.1% | 97.4% |\n",
        "| Adamw | 97.3% | 95.2% #(some bug here maybe) |"
      ],
      "metadata": {
        "id": "LpZsDIg66mGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "CuNPTHMiWrNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "vDtwSTaQWu0V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = NeuralNetwork().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0)\n",
        "print(model)\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtbzwOBXW1br",
        "outputId": "e02f378e-ab4d-4425-d656-3dd078bbb0e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.298019  [   64/60000]\n",
            "loss: 0.286682  [ 6464/60000]\n",
            "loss: 0.202501  [12864/60000]\n",
            "loss: 0.220391  [19264/60000]\n",
            "loss: 0.151500  [25664/60000]\n",
            "loss: 0.319747  [32064/60000]\n",
            "loss: 0.109737  [38464/60000]\n",
            "loss: 0.230567  [44864/60000]\n",
            "loss: 0.323673  [51264/60000]\n",
            "loss: 0.177040  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.131311 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.070882  [   64/60000]\n",
            "loss: 0.072354  [ 6464/60000]\n",
            "loss: 0.099273  [12864/60000]\n",
            "loss: 0.084804  [19264/60000]\n",
            "loss: 0.036386  [25664/60000]\n",
            "loss: 0.150246  [32064/60000]\n",
            "loss: 0.047423  [38464/60000]\n",
            "loss: 0.143967  [44864/60000]\n",
            "loss: 0.130274  [51264/60000]\n",
            "loss: 0.134730  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099002 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.039202  [   64/60000]\n",
            "loss: 0.073761  [ 6464/60000]\n",
            "loss: 0.050660  [12864/60000]\n",
            "loss: 0.072049  [19264/60000]\n",
            "loss: 0.073876  [25664/60000]\n",
            "loss: 0.106550  [32064/60000]\n",
            "loss: 0.041766  [38464/60000]\n",
            "loss: 0.074438  [44864/60000]\n",
            "loss: 0.114012  [51264/60000]\n",
            "loss: 0.089998  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.100955 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.012462  [   64/60000]\n",
            "loss: 0.052899  [ 6464/60000]\n",
            "loss: 0.045229  [12864/60000]\n",
            "loss: 0.049632  [19264/60000]\n",
            "loss: 0.017876  [25664/60000]\n",
            "loss: 0.073655  [32064/60000]\n",
            "loss: 0.025131  [38464/60000]\n",
            "loss: 0.058793  [44864/60000]\n",
            "loss: 0.101778  [51264/60000]\n",
            "loss: 0.048446  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.139686 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.033544  [   64/60000]\n",
            "loss: 0.028203  [ 6464/60000]\n",
            "loss: 0.058364  [12864/60000]\n",
            "loss: 0.037122  [19264/60000]\n",
            "loss: 0.024306  [25664/60000]\n",
            "loss: 0.014270  [32064/60000]\n",
            "loss: 0.020952  [38464/60000]\n",
            "loss: 0.065213  [44864/60000]\n",
            "loss: 0.012358  [51264/60000]\n",
            "loss: 0.043472  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.112053 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with default optimizer"
      ],
      "metadata": {
        "id": "EzGxcpomV9O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import optimizer as optim\n",
        "importlib.reload(optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGI-vgO_YyTu",
        "outputId": "610dbd99-101b-4f14-e90b-2a188861dcfd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'optimizer' from '/content/optimizer.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = NeuralNetwork().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "# optimizer = optim.Momentum(model.parameters(), lr=1e-3)\n",
        "# optimizer = optim.Nestrov(model.parameters(), lr=1e-3)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = optim.Nadam(model.parameters(), lr=1e-3)\n",
        "optimizer = optim.Adamw(model.parameters(), lr=1e-3)\n",
        "print(model)\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfPCEWJLT3tk",
        "outputId": "af450f4f-07cf-451f-e5fb-9d10c501997f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.306578  [   64/60000]\n",
            "loss: 0.434851  [ 6464/60000]\n",
            "loss: 0.335383  [12864/60000]\n",
            "loss: 0.333054  [19264/60000]\n",
            "loss: 0.249722  [25664/60000]\n",
            "loss: 0.323282  [32064/60000]\n",
            "loss: 0.218301  [38464/60000]\n",
            "loss: 0.352347  [44864/60000]\n",
            "loss: 0.363521  [51264/60000]\n",
            "loss: 0.284657  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.231945 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.173764  [   64/60000]\n",
            "loss: 0.212814  [ 6464/60000]\n",
            "loss: 0.147696  [12864/60000]\n",
            "loss: 0.223761  [19264/60000]\n",
            "loss: 0.168054  [25664/60000]\n",
            "loss: 0.258198  [32064/60000]\n",
            "loss: 0.151443  [38464/60000]\n",
            "loss: 0.279695  [44864/60000]\n",
            "loss: 0.280201  [51264/60000]\n",
            "loss: 0.218887  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.190423 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.139636  [   64/60000]\n",
            "loss: 0.166290  [ 6464/60000]\n",
            "loss: 0.134852  [12864/60000]\n",
            "loss: 0.184668  [19264/60000]\n",
            "loss: 0.134338  [25664/60000]\n",
            "loss: 0.226674  [32064/60000]\n",
            "loss: 0.139099  [38464/60000]\n",
            "loss: 0.255481  [44864/60000]\n",
            "loss: 0.262929  [51264/60000]\n",
            "loss: 0.194196  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.173997 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.125719  [   64/60000]\n",
            "loss: 0.147294  [ 6464/60000]\n",
            "loss: 0.132309  [12864/60000]\n",
            "loss: 0.163750  [19264/60000]\n",
            "loss: 0.122547  [25664/60000]\n",
            "loss: 0.211357  [32064/60000]\n",
            "loss: 0.136245  [38464/60000]\n",
            "loss: 0.243780  [44864/60000]\n",
            "loss: 0.260676  [51264/60000]\n",
            "loss: 0.180642  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.165394 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.120192  [   64/60000]\n",
            "loss: 0.137314  [ 6464/60000]\n",
            "loss: 0.131638  [12864/60000]\n",
            "loss: 0.156868  [19264/60000]\n",
            "loss: 0.116805  [25664/60000]\n",
            "loss: 0.200337  [32064/60000]\n",
            "loss: 0.133828  [38464/60000]\n",
            "loss: 0.233751  [44864/60000]\n",
            "loss: 0.259577  [51264/60000]\n",
            "loss: 0.174229  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.160818 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jcDeGYbyqLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note for Nadam\n",
        "\n",
        "the implementation of nadam in this code referenced the paper \"An overview of gradient descent optimization algorithms\""
      ],
      "metadata": {
        "id": "a3qOwYQ3EyFx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CeAB9wetE-9e"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}